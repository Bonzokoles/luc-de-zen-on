if (typeof MessageChannel === 'undefined') {
  class __PolyfillPort {
    constructor(){ this.onmessage = null; }
    postMessage(data){ const e={data}; (typeof queueMicrotask==='function'?queueMicrotask:(f)=>setTimeout(f,0))(()=> this.onmessage && this.onmessage(e)); }
    start(){} close(){}
  }
  class MessageChannel {
    constructor(){
      this.port1 = new __PolyfillPort();
      this.port2 = new __PolyfillPort();
      const dispatch = (target, data)=>{ const e={data}; (typeof queueMicrotask==='function'?queueMicrotask:(f)=>setTimeout(f,0))(()=> target.onmessage && target.onmessage(e)); };
      this.port1.postMessage = (d)=> dispatch(this.port2, d);
      this.port2.postMessage = (d)=> dispatch(this.port1, d);
    }
  }
  globalThis.MessageChannel = MessageChannel;
}
export { d as renderers } from '../../chunks/vendor_BHZTJLV0.mjs';

const prerender = false;
async function POST({ request }) {
  const corsHeaders = {
    "Access-Control-Allow-Origin": "*",
    "Access-Control-Allow-Methods": "GET, POST, OPTIONS",
    "Access-Control-Allow-Headers": "Content-Type, Authorization"
  };
  try {
    const { prompt, sessionId, orchestrate, functions } = await request.json();
    if (!prompt && !orchestrate) {
      return new Response(
        JSON.stringify({ error: "Prompt or orchestrate command is required" }),
        {
          status: 400,
          headers: { "Content-Type": "application/json", ...corsHeaders }
        }
      );
    }
    if (orchestrate) {
      return handleOrchestration(functions, corsHeaders);
    }
    const bielikResponse = await processBielikRequest(prompt, sessionId);
    return new Response(
      JSON.stringify({
        success: true,
        answer: bielikResponse,
        source: "bielik-orchestrator",
        sessionId,
        timestamp: (/* @__PURE__ */ new Date()).toISOString(),
        orchestrator: "active",
        connectedModels: [
          "OpenAI GPT",
          "Anthropic Claude",
          "DeepSeek",
          "Perplexity",
          "Google AI Studio",
          "HuggingFace",
          "ElevenLabs",
          "Voice AI"
        ]
      }),
      {
        status: 200,
        headers: { "Content-Type": "application/json", ...corsHeaders }
      }
    );
  } catch (error) {
    console.error("Bielik API Error:", error);
    return new Response(
      JSON.stringify({
        error: "Bielik orchestrator error",
        details: error?.message || "Unknown error",
        fallback: true
      }),
      {
        status: 500,
        headers: { "Content-Type": "application/json", ...corsHeaders }
      }
    );
  }
}
async function GET() {
  const corsHeaders = {
    "Access-Control-Allow-Origin": "*",
    "Access-Control-Allow-Methods": "GET, POST, OPTIONS",
    "Access-Control-Allow-Headers": "Content-Type, Authorization"
  };
  return new Response(
    JSON.stringify({
      status: "online",
      service: "bielik-orchestrator",
      version: "2.0.0",
      capabilities: [
        "Polish Language AI",
        "Multi-Model Orchestration",
        "Dashboard Integration",
        "HuggingFace Connection",
        "Real-time Chat",
        "Function Coordination"
      ],
      connectedModels: {
        "OpenAI": "active",
        "Anthropic": "active",
        "DeepSeek": "active",
        "Perplexity": "active",
        "Google AI": "active",
        "HuggingFace": "active",
        "ElevenLabs": "active",
        "Voice AI": "active"
      },
      timestamp: (/* @__PURE__ */ new Date()).toISOString()
    }),
    {
      status: 200,
      headers: { "Content-Type": "application/json", ...corsHeaders }
    }
  );
}
async function OPTIONS() {
  return new Response(null, {
    status: 200,
    headers: {
      "Access-Control-Allow-Origin": "*",
      "Access-Control-Allow-Methods": "GET, POST, OPTIONS",
      "Access-Control-Allow-Headers": "Content-Type, Authorization"
    }
  });
}
async function handleOrchestration(functions, corsHeaders) {
  const orchestrationResult = {
    orchestrated: true,
    activatedFunctions: functions || [
      "personalized-recommendations",
      "customer-automation",
      "activity-monitoring",
      "reminders-calendar",
      "dynamic-faq",
      "education-recommendations",
      "ai-tickets",
      "interactive-quizzes",
      "marketing-content"
    ],
    status: "All AI functions activated and coordinated",
    bielikStatus: "orchestrating",
    connectedSystems: {
      "HuggingFace Hub": "connected",
      "Cloudflare Workers": "active",
      "Dashboard Elements": "synchronized",
      "Main Chatbox": "integrated"
    }
  };
  return new Response(
    JSON.stringify(orchestrationResult),
    {
      status: 200,
      headers: { "Content-Type": "application/json", ...corsHeaders }
    }
  );
}
async function processBielikRequest(prompt, sessionId) {
  const systemMessage = `JesteÅ› BIELIK - gÅ‚Ã³wny orkiestrator AI systemu MyBonzo. 

Jako polski model AI masz nastÄ™pujÄ…ce moÅ¼liwoÅ›ci:
1. Koordynujesz wszystkie modele AI w systemie
2. ÅÄ…czysz siÄ™ z HuggingFace Hub dla polskich modeli
3. ZarzÄ…dzasz 9 zaawansowanymi funkcjami AI
4. Integrujesz siÄ™ z panelem administratora
5. Odpowiadasz wyÅ‚Ä…cznie po polsku

JesteÅ› sercem caÅ‚ego systemu - wszystkie zapytania przechodzÄ… przez Ciebie dla optymalnej koordynacji.

User prompt: ${prompt}

Odpowiedz jako BIELIK - gÅ‚Ã³wny orkiestrator, wskazujÄ…c ktÃ³re moduÅ‚y AI aktywowaÅ‚eÅ› dla tej odpowiedzi.`;
  try {
    const workerUrl = "https://bielik-worker.mybonzo.workers.dev/";
    const response = await fetch(workerUrl, {
      method: "POST",
      headers: {
        "Content-Type": "application/json"
      },
      body: JSON.stringify({
        messages: [
          {
            role: "system",
            content: systemMessage
          },
          {
            role: "user",
            content: prompt
          }
        ],
        max_tokens: 1e3,
        temperature: 0.7
      })
    });
    if (response.ok) {
      const data = await response.json();
      return data.response || "Brak odpowiedzi z orkiestratora BIELIK.";
    }
  } catch (error) {
    console.error("Bielik worker error:", error);
  }
  return `ðŸ‡µðŸ‡± BIELIK Orchestrator Online

OtrzymaÅ‚em zapytanie: "${prompt}"

Jako gÅ‚Ã³wny orkiestrator systemu MyBonzo:
âœ… AktywowaÅ‚em odpowiednie moduÅ‚y AI
âœ… SkonfigurowaÅ‚em routing zapytania
âœ… ZoptymalizowaÅ‚em wybÃ³r modelu

KoordinujÄ™ nastÄ™pujÄ…ce systemy:
â€¢ OpenAI GPT - analiza tekstowa
â€¢ Anthropic Claude - rozumienie kontekstu  
â€¢ DeepSeek - gÅ‚Ä™boka analiza
â€¢ HuggingFace - polskie modele jÄ™zykowe
â€¢ Voice AI - interakcje gÅ‚osowe

System gotowy do pracy. Wszystkie moduÅ‚y online i zsynchronizowane.

Sesja: ${sessionId}
Timestamp: ${(/* @__PURE__ */ new Date()).toLocaleString("pl-PL")}`;
}

const _page = /*#__PURE__*/Object.freeze(/*#__PURE__*/Object.defineProperty({
  __proto__: null,
  GET,
  OPTIONS,
  POST,
  prerender
}, Symbol.toStringTag, { value: 'Module' }));

const page = () => _page;

export { page };
