# üîó HuggingFace Repositories - Quick Reference

**Data:** 2026-02-09  
**Projekt:** ZENON_Biznes_HUB  
**Cel:** Szybki dostƒôp do repozytori√≥w modeli HuggingFace dla MiniHelpers

---

## üì¶ Rekomendowane Repozytoria

### 1. SmolLM (Small Language Models)
**GitHub:** https://github.com/huggingface/smollm  
**Model:** https://huggingface.co/HuggingFaceTB/SmolLM2-1.7B-Instruct  
**Licencja:** Apache 2.0  
**Rozmiar:** 1.7B parametr√≥w (~4GB RAM)  
**Jƒôzyk:** EN, PL (czƒô≈õciowo)  
**U≈ºycie:** Lekki LLM do klasyfikacji, generowania, Q&A

---

### 2. Sentence Transformers - all-MiniLM-L6-v2
**Repo:** https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2  
**Licencja:** Apache 2.0  
**Rozmiar:** ~80MB  
**Embeddings:** 384 wymiary  
**U≈ºycie:** Semantic search, clustering, similarity

---

### 3. BGE Small English
**Repo:** https://huggingface.co/BAAI/bge-small-en-v1.5  
**Licencja:** MIT  
**Rozmiar:** ~133MB  
**Embeddings:** 384 wymiary  
**U≈ºycie:** Retrieval, RAG, semantic search

---

### 4. Xenova GTE Small (ONNX)
**Repo:** https://huggingface.co/Xenova/gte-small  
**Licencja:** Apache 2.0  
**Rozmiar:** ~120MB  
**Format:** ONNX (szybki w przeglƒÖdarce!)  
**U≈ºycie:** Client-side embeddings, offline mode

---

### 5. Polish RoBERTa Base v2 üáµüá±
**Repo:** https://huggingface.co/sdadas/polish-roberta-base-v2  
**Licencja:** CC BY-SA 4.0  
**Rozmiar:** ~500MB  
**Jƒôzyk:** Polski (natywnie)  
**U≈ºycie:** Sentiment analysis, NER, classification (polski)

---

### 6. Bielik-11B v2.2 Instruct üáµüá± (ju≈º zaplanowany)
**Repo:** https://huggingface.co/speakleash/Bielik-11B-v2.2-Instruct  
**Licencja:** Apache 2.0  
**Rozmiar:** 11.2B parametr√≥w  
**Jƒôzyk:** Polski (natywnie)  
**U≈ºycie:** Voice assistant, orchestrator, g≈Ç√≥wny polski LLM  
**Status:** ‚úÖ Dokumentacja w `GATEWAY_BIELIK_SETUP.md`

---

## üõ†Ô∏è Helper Libraries & Tools

### 1. Text Embeddings Inference (TEI)
**GitHub:** https://github.com/huggingface/text-embeddings-inference  
**Opis:** Blazing fast inference dla text embeddings  
**Features:** Docker, GPU support, high-throughput  
**U≈ºycie:** Self-hosted embedding service

---

### 2. Transformers.js
**GitHub:** https://github.com/xenova/transformers.js  
**NPM:** `@xenova/transformers`  
**Opis:** Transformers w przeglƒÖdarce (ONNX Runtime)  
**Features:** Offline, privacy-first, no API calls  
**U≈ºycie:** Client-side ML

---

### 3. HuggingFace.js
**GitHub:** https://github.com/huggingface/huggingface.js  
**NPM:** `@huggingface/inference`  
**Opis:** Oficjalny JS client dla HF Inference API  
**U≈ºycie:** Server-side calls do HF API

---

## üìö Datasets (opcjonalne)

### Polish Reviews Dataset
**Repo:** https://huggingface.co/datasets/clarin-pl/polemo2-official  
**Opis:** Polski dataset opinii (sentiment)  
**U≈ºycie:** Fine-tuning modeli sentymentu

---

### Polish Wikipedia
**Repo:** https://huggingface.co/datasets/wikipedia  
**Config:** `pl` (20240301)  
**U≈ºycie:** Training/fine-tuning polskich embeddings

---

## ‚ö° Quick Start Commands

### Install HuggingFace JS Client
```bash
npm install @huggingface/inference
```

### Install Transformers.js (client-side)
```bash
npm install @xenova/transformers
```

### Python (local testing)
```bash
pip install transformers sentence-transformers
```

---

## üîë Authentication

**Token:** https://huggingface.co/settings/tokens  
**Variable:** `HF_TOKEN` (environment)  
**Cloudflare:** 
```bash
npx wrangler pages secret put HF_TOKEN --project-name=luc-de-zen-on
```

---

## üìä API Endpoints

### HuggingFace Inference API
**Base URL:** `https://api-inference.huggingface.co/models/`  
**Example:** `https://api-inference.huggingface.co/models/sentence-transformers/all-MiniLM-L6-v2`

**Rate Limits:**
- Free: ~1000 requests/day
- PRO: Higher limits + priority

### Cloudflare AI Gateway (for caching)
**Pattern:** `https://gateway.ai.cloudflare.com/v1/{account_id}/{gateway_name}/huggingface/{model_id}`

---

## üéØ Use Cases Mapping

| Przypadek u≈ºycia | Rekomendowany model | Repo |
|------------------|---------------------|------|
| Semantic search | all-MiniLM-L6-v2 | [Link](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2) |
| Polish sentiment | polish-roberta-base-v2 | [Link](https://huggingface.co/sdadas/polish-roberta-base-v2) |
| Text classification | SmolLM2-1.7B | [Link](https://huggingface.co/HuggingFaceTB/SmolLM2-1.7B-Instruct) |
| Client-side embeddings | Xenova/gte-small | [Link](https://huggingface.co/Xenova/gte-small) |
| RAG/Retrieval | bge-small-en-v1.5 | [Link](https://huggingface.co/BAAI/bge-small-en-v1.5) |
| Polish LLM | Bielik-11B-v2.2 | [Link](https://huggingface.co/speakleash/Bielik-11B-v2.2-Instruct) |

---

## üìù Notes

- Wszystkie modele Apache 2.0/MIT = OK dla u≈ºytku komercyjnego
- Polish RoBERTa = CC BY-SA 4.0 (attribution required)
- SmolLM + Xenova = najlepsze dla local/edge deployment
- Bielik = najlepszy dla polskiego jƒôzyka (large model)
- all-MiniLM = najszybszy dla embeddings

---

**Ostatnia aktualizacja:** 2026-02-09  
**Related docs:** `HUGGINGFACE_MINICHELPERS.md`, `GATEWAY_BIELIK_SETUP.md`
