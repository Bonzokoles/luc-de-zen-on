import type { APIRoute } from 'astro';

// Chat history tracking
const snellChatHistory: Array<{
  id: string;
  messages: Array<{ role: string; content: string; timestamp: number }>;
  model: string;
  timestamp: number;
}> = [];

// Snell AI model information (hypothetical free AI model)
const SNELL_MODELS = {
  'snell-chat': {
    name: 'Snell Chat',
    description: 'Szybki model do konwersacji - darmowy',
    context_length: 4096,
    specializes: ['rozmowy', 'pytania', 'asystent'],
    free: true
  },
  'snell-code': {
    name: 'Snell Code',
    description: 'Model zoptymalizowany pod programowanie',
    context_length: 8192,
    specializes: ['programowanie', 'debugging', 'kod'],
    free: true
  },
  'snell-creative': {
    name: 'Snell Creative',
    description: 'Model do twÃ³rczego pisania i historii',
    context_length: 6144,
    specializes: ['pisanie', 'historie', 'kreatywnoÅ›Ä‡'],
    free: true
  }
};

// AI Functions for Snell
async function getSnellInstructions() {
  return {
    title: 'Snell AI API - Darmowy szybki asystent AI',
    description: 'BezpÅ‚atne modele Snell AI do rÃ³Å¼nych zastosowaÅ„',
    sections: {
      'DostÄ™pne modele': SNELL_MODELS,
      'Funkcje': {
        chat: 'Naturalne rozmowy i odpowiedzi na pytania',
        coding: 'Pomoc w programowaniu i debugging',
        creative: 'TwÃ³rcze pisanie i generowanie treÅ›ci',
        analysis: 'Analiza tekstu i danych',
        translation: 'Podstawowe tÅ‚umaczenia',
        summarization: 'Streszczanie dÅ‚ugich tekstÃ³w'
      },
      'Parametry POST': {
        message: 'string (wymagane) - wiadomoÅ›Ä‡ uÅ¼ytkownika',
        model: 'string - model snell (domyÅ›lnie snell-chat)',
        temperature: 'number - kreatywnoÅ›Ä‡ 0.0-1.0 (domyÅ›lnie 0.7)',
        max_tokens: 'number - maksymalna dÅ‚ugoÅ›Ä‡ odpowiedzi',
        system_prompt: 'string - instrukcje systemowe',
        conversation_id: 'string - ID konwersacji do kontynuacji',
        stream: 'boolean - czy streamowaÄ‡ odpowiedÅº'
      }
    },
    examples: {
      'Prosta rozmowa': '{"message": "Co to jest AI?", "model": "snell-chat"}',
      'Pomoc w kodzie': '{"message": "Jak napisaÄ‡ pÄ™tlÄ™ for w JavaScript?", "model": "snell-code"}',
      'Kreatywne pisanie': '{"message": "Napisz krÃ³tkÄ… historiÄ™ o robocie", "model": "snell-creative", "temperature": 0.9}',
      'Z systemem': '{"message": "Przeanalizuj ten kod", "system_prompt": "JesteÅ› ekspertem programowania", "model": "snell-code"}'
    },
    best_practices: {
      models: 'snell-chat do rozmÃ³w, snell-code do programowania, snell-creative do pisania',
      temperature: 'NiÅ¼sza temperatura = bardziej precyzyjne odpowiedzi',
      context: 'UÅ¼ywaj system_prompt dla lepszego kontekstu',
      conversations: 'UÅ¼ywaj conversation_id dla ciÄ…gÅ‚oÅ›ci rozmowy'
    }
  };
}

async function getSnellAIHelp(env: any, question: string) {
  try {
    const prompt = `JesteÅ› ekspertem od modeli Snell AI i szybkich asystentÃ³w AI. 
    UÅ¼ytkownik pyta: "${question}"
    
    PomÃ³Å¼ uÅ¼ytkownikowi z:
    - Wyborem wÅ‚aÅ›ciwego modelu Snell (chat/code/creative)
    - OptymalizacjÄ… promptÃ³w i parametrÃ³w
    - RozwiÄ…zywaniem problemÃ³w z API
    - Najlepszymi praktykami uÅ¼ywania Snell AI
    
    Odpowiedz po polsku z konkretnymi wskazÃ³wkami.`;

    if (env.AI) {
      const response = await env.AI.run('@cf/meta/llama-3.1-8b-instruct', {
        messages: [{ role: 'user', content: prompt }]
      });
      return response.response || 'Nie udaÅ‚o siÄ™ uzyskaÄ‡ odpowiedzi AI';
    }
    
    return 'AI obecnie niedostÄ™pne. Model Snell jest szybki i prosty w uÅ¼yciu - wybierz model do zadania.';
  } catch (error) {
    return `BÅ‚Ä…d AI: ${error instanceof Error ? error.message : 'Nieznany bÅ‚Ä…d'}`;
  }
}

function generateChatId(): string {
  return 'snell_' + Date.now().toString(36) + Math.random().toString(36).substr(2);
}

export const GET: APIRoute = async ({ request, locals }) => {
  try {
    const url = new URL(request.url);
    const instructions = url.searchParams.get('instructions');
    const aiHelp = url.searchParams.get('ai_help');
    const models = url.searchParams.get('models');
    const conversationId = url.searchParams.get('conversation_id');
    
    const env =
      (locals as any)?.runtime?.env ??
      (globalThis as any).cloudflareEnv ??
      {};

    // Handle models list request
    if (models) {
      return new Response(JSON.stringify({
        success: true,
        service: 'Snell AI - DostÄ™pne modele',
        models: SNELL_MODELS,
        count: Object.keys(SNELL_MODELS).length,
        timestamp: new Date().toISOString()
      }), {
        headers: { 'Content-Type': 'application/json' }
      });
    }

    // Handle instructions request
    if (instructions) {
      const snellInstructions = await getSnellInstructions();
      return new Response(JSON.stringify({
        success: true,
        service: 'Snell AI - Instrukcje',
        instructions: snellInstructions,
        timestamp: new Date().toISOString()
      }), {
        headers: { 'Content-Type': 'application/json' }
      });
    }

    // Handle AI help request
    if (aiHelp) {
      const aiResponse = await getSnellAIHelp(env, aiHelp);
      return new Response(JSON.stringify({
        success: true,
        service: 'Snell AI Assistant',
        question: aiHelp,
        ai_response: aiResponse,
        timestamp: new Date().toISOString()
      }), {
        headers: { 'Content-Type': 'application/json' }
      });
    }

    // Get conversation history
    if (conversationId) {
      const conversation = snellChatHistory.find(c => c.id === conversationId);
      return new Response(JSON.stringify({
        success: true,
        service: 'Snell AI Conversation History',
        conversation_id: conversationId,
        conversation: conversation || null,
        timestamp: new Date().toISOString()
      }), {
        headers: { 'Content-Type': 'application/json' }
      });
    }

    // Default help response
    return new Response(JSON.stringify({
      success: true,
      service: 'Snell AI API - Darmowy szybki asystent',
      help: {
        description: 'BezpÅ‚atne modele Snell AI do rÃ³Å¼nych zastosowaÅ„',
        models: Object.keys(SNELL_MODELS),
        features: ['Szybkie odpowiedzi', 'RÃ³Å¼ne specjalizacje', 'Darmowe uÅ¼ytkowanie'],
        methods: {
          GET: 'Instrukcje, pomoc AI, modele i historia',
          POST: 'Rozmowy z modelami Snell'
        },
        parameters: {
          instructions: 'SzczegÃ³Å‚owe instrukcje API',
          ai_help: 'Zadaj pytanie o modele Snell',
          models: 'Lista dostÄ™pnych modeli',
          conversation_id: 'Pobierz historiÄ™ konwersacji'
        },
        examples: {
          help: '?ai_help=KtÃ³ry model Snell wybraÄ‡ do analizy kodu?',
          instructions: '?instructions=true',
          models: '?models=true',
          history: '?conversation_id=snell_123abc'
        }
      },
      timestamp: new Date().toISOString()
    }), {
      headers: { 'Content-Type': 'application/json' }
    });

  } catch (error) {
    return new Response(JSON.stringify({
      success: false,
      service: 'Snell AI',
      error: error instanceof Error ? error.message : 'Nieznany bÅ‚Ä…d'
    }), {
      status: 500,
      headers: { 'Content-Type': 'application/json' }
    });
  }
};

export const POST: APIRoute = async ({ request, locals }) => {
  try {
    const data = await request.json();
    const { 
      message, 
      model = 'snell-chat', 
      temperature = 0.7,
      max_tokens = 1024,
      system_prompt = '',
      conversation_id,
      stream = false
    } = data;
    
    const env = (locals as any)?.runtime?.env;
    
    if (!message) {
      return new Response(JSON.stringify({
        success: false,
        service: 'Snell AI Chat',
        error: 'Brak wiadomoÅ›ci',
        message: 'Wymagana jest wiadomoÅ›Ä‡ do rozmowy'
      }), {
        status: 400,
        headers: { 'Content-Type': 'application/json' }
      });
    }

    // Validate model
    if (!SNELL_MODELS[model as keyof typeof SNELL_MODELS]) {
      return new Response(JSON.stringify({
        success: false,
        service: 'Snell AI Chat',
        error: 'Nieznany model',
        message: `DostÄ™pne modele: ${Object.keys(SNELL_MODELS).join(', ')}`
      }), {
        status: 400,
        headers: { 'Content-Type': 'application/json' }
      });
    }

    const startTime = Date.now();
    
    // Find or create conversation
    let conversation = conversation_id ? 
      snellChatHistory.find(c => c.id === conversation_id) : null;
    
    if (!conversation) {
      conversation = {
        id: conversation_id || generateChatId(),
        messages: [],
        model,
        timestamp: Date.now()
      };
      snellChatHistory.unshift(conversation);
    }

    // Add system prompt if provided
    if (system_prompt && conversation.messages.length === 0) {
      conversation.messages.push({
        role: 'system',
        content: system_prompt,
        timestamp: Date.now()
      });
    }

    // Add user message
    conversation.messages.push({
      role: 'user',
      content: message,
      timestamp: Date.now()
    });

    // Generate response with Snell AI (simulated)
    let aiResponse = await generateSnellResponse(model, message, conversation.messages, {
      temperature,
      max_tokens,
      system_prompt
    });

    // Add AI response to conversation
    conversation.messages.push({
      role: 'assistant',
      content: aiResponse,
      timestamp: Date.now()
    });

    const executionTime = Date.now() - startTime;
    const modelInfo = SNELL_MODELS[model as keyof typeof SNELL_MODELS];

    // Keep conversations manageable
    if (snellChatHistory.length > 50) {
      snellChatHistory.pop();
    }

    // Limit messages per conversation
    if (conversation.messages.length > 50) {
      conversation.messages = conversation.messages.slice(-30);
    }
    
    return new Response(JSON.stringify({
      success: true,
      service: 'Snell AI Chat',
      model: model,
      model_info: modelInfo,
      conversation_id: conversation.id,
      user_message: message,
      ai_response: aiResponse,
      conversation_length: conversation.messages.length,
      execution_time_ms: executionTime,
      parameters: {
        model,
        temperature,
        max_tokens,
        system_prompt: system_prompt ? 'Ustawiony' : 'Brak',
        stream
      },
      timestamp: new Date().toISOString()
    }), {
      headers: { 'Content-Type': 'application/json' }
    });

  } catch (error) {
    return new Response(JSON.stringify({
      success: false,
      service: 'Snell AI Chat',
      error: error instanceof Error ? error.message : 'Nieznany bÅ‚Ä…d rozmowy'
    }), {
      status: 500,
      headers: { 'Content-Type': 'application/json' }
    });
  }
};

async function generateSnellResponse(model: string, message: string, history: any[], options: any): Promise<string> {
  // Simulate Snell AI processing time (very fast)
  await new Promise(resolve => setTimeout(resolve, 200 + Math.random() * 800));
  
  const modelInfo = SNELL_MODELS[model as keyof typeof SNELL_MODELS];
  
  // Simulate different response styles based on model
  if (model === 'snell-code') {
    return `Jako Snell Code, specjalizujÄ™ siÄ™ w programowaniu. 

OdpowiadajÄ…c na: "${message}"

Oto moja analiza i sugestie dotyczÄ…ce kodu/programowania:
- SprawdzÄ™ skÅ‚adniÄ™ i strukturÄ™
- ZaproponujÄ™ optymalizacje
- WskaÅ¼Ä™ potencjalne problemy
- Podam przykÅ‚ady uÅ¼ycia

[To jest symulowana odpowiedÅº Snell Code - w rzeczywistoÅ›ci uÅ¼ywaÅ‚by prawdziwego modelu AI zoptymalizowanego pod kod]`;
  }
  
  if (model === 'snell-creative') {
    return `Jako Snell Creative, uwielbiam tworzyÄ‡! âœ¨

Na temat: "${message}"

PozwÃ³l mi stworzyÄ‡ coÅ› inspirujÄ…cego:
- Oryginalne pomysÅ‚y i koncepcje  
- Kreatywne podejÅ›cie do tematu
- AngaÅ¼ujÄ…ce historie i opisy
- Artystyczne rozwiÄ…zania

[To jest symulowana odpowiedÅº Snell Creative - w prawdziwym modelu byÅ‚aby to twÃ³rcza, oryginalna treÅ›Ä‡]`;
  }
  
  // Default snell-chat response
  return `CzeÅ›Ä‡! Jestem Snell Chat - szybki i pomocny asystent AI. ğŸ¤–

Pytasz o: "${message}"

Oto moja odpowiedÅº:
- Postaram siÄ™ pomÃ³c w jasny sposÃ³b
- Odpowiem szybko i konkretnie  
- JeÅ›li potrzebujesz wiÄ™cej szczegÃ³Å‚Ã³w, pytaj Å›miaÅ‚o
- MogÄ™ pomÃ³c z rÃ³Å¼nymi tematami

Czy jest coÅ› konkretnego, z czym mogÄ™ dalej pomÃ³c?

[To jest symulowana odpowiedÅº Snell Chat - prawdziwy model daÅ‚by bardziej naturalnÄ… konwersacjÄ™]`;
}